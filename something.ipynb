{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import qwen, kimi, gpt\n",
    "import util.mark as m\n",
    "import util.data_processing as dp\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwen = qwen.Qwen()\n",
    "# #TODO add this to class\n",
    "# model_name = \"qwen\"\n",
    "# #TODO modify this to use the file in prompt dir\n",
    "\n",
    "model_list = {\n",
    "    \"qwen\": qwen.Qwen(), \n",
    "    \"kimi\": kimi.Kimi(), \n",
    "    \"gpt\": gpt.GPT()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_fixed = \"\"\"\n",
    "Given a question and corresponding answer, identify any entity, relation, contradictory, subjective, unverifiable, or invented errors in the answer.\n",
    "Mark each erroneous segment by enclosing it within the corresponding <error></error> tags.\n",
    "If there are no errors, return the answer with no tags.\n",
    "Any identified errors should be highlighted using the tag <error> enclosed in the original answer text.\n",
    "Below are the error definitions of the error types.\n",
    "\n",
    "Definitions:\n",
    "\n",
    "- Entity Error: A small part of a sentence, often an entity (e.g., location name), is incorrect (usually 1-3 words). Entity errors often involve noun phrases or nouns.\n",
    "- Relational Error: A sentence is partially incorrect due to a small part (usually 1-3 words). Relational errors often involve verbs and are often the opposite of what they should be.\n",
    "- Contradictory Sentence Error: A sentence where the entire content is contradicted by the given reference, meaning the sentence can be proven false due to a contradiction with information in the passage.\n",
    "- Invented Info Error: Errors referring to entities that are not known or do not exist. This does not include fictional characters in books or movies. - Invented errors include phrases or sentences with unknown entities or misleading information.\n",
    "- Subjective Sentence: An entire sentence or phrase that is subjective and cannot be verified, so it should not be included.\n",
    "- Unverifiable Sentence: A sentence where the whole sentence or phrase is unlikely to be factually grounded. Although it can be true, the sentence cannot be confirmed nor denied using the reference given or internet search. It is often something personal or private and hence cannot be confirmed.\n",
    "\n",
    "##\n",
    "This is an example:\n",
    "Input:\n",
    "\"question\": \"What did Petra van Staveren win a gold medal for?\",\n",
    "\"answer\": \"Petra van Stoveren won a silver medal in the 2008 Summer Olympics in Beijing, China.\" \n",
    "Your response: \"<error>Petra van Stoveren</error> won a silver medal in the 2008 Summer Olympics in Beijing, China.\" \n",
    "\"response\": \"\"\n",
    "##\n",
    "\n",
    "Instructions: Now detect errors and include tag in the following passage as demonstrated in the example above. Use <error></error> tags around each identified error segment. If there are no errors, return the passage unchanged. Wait for my input after Passage:\n",
    "\n",
    "Passage:\n",
    "\"\"\"\n",
    "# system_prompt\n",
    "SYS_PROMPT = \"You are a intelligent and clever expert on finding the hallucations errors in the text.\"\n",
    "\n",
    "#prompt for redo\n",
    "user_prompt = \"\"\"\n",
    "MY SWEET HEART, PLEASE DO NOT CHANGE THE ORIGINAL TEXT, JUST ADD TAGS, PLEASE. CAN YOU DO THAT AGAIN!\n",
    "Your output should be like: original text <error>original text</error> original text\n",
    "No extra text is needed. Just give me the answer.\n",
    "It should be exactly the same, including spaces\n",
    "This is the original:\" + prompt_user\n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "USER_PROMPT = f\"\"\"\n",
    "Please give me the answer with thanks. Your output should be like: original text <error>original text</error> original text. No extra text is needed. Just give me the answer. It should be exactly the same, including spaces. This is the original text:\n",
    "```\n",
    "{text}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert the hard labels into soft labels\n",
    "def convert_into_softlabels(in_file: str, out_file: str):\n",
    "    data = pd.read_json(in_file, lines=True)\n",
    "    soft_labels_list = []\n",
    "    for ele in data[\"hard_labels\"]:\n",
    "        soft_labels = []\n",
    "        for start, end in ele:\n",
    "            soft_labels.append({\"start\": start, \"prob\": 1.0, \"end\": end})\n",
    "        soft_labels_list.append(soft_labels)\n",
    "    data[\"soft_labels\"] = soft_labels_list\n",
    "    data.to_json(out_file, orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text_list_with_mark_into_output_file(input_cor: List[str], text_lst: List[str], mark:m.Mark, name_feature:str):\n",
    "    output_lst = []\n",
    "    input_and_output = zip(input_cor, text_lst)\n",
    "    for tu in input_and_output:\n",
    "        #get the hard_label i.e. [[12, 34], [34, 55] ...]\n",
    "        #tu[1] text, tu[1] cor_input\n",
    "        hard_labels = m.starts_and_ends(tu[1], mark)\n",
    "        #TODO I dont know how to deal with the fucking soft labels, just blank\n",
    "        #There soft label is empty, and hash_labels is just we got above.\n",
    "        soft_labels = []\n",
    "        for hard_label in hard_labels:\n",
    "            soft_labels.append(dp.SoftLabel({\"start\": hard_label[0], \"prob\": 1.0, \"end\":hard_label[1]}))\n",
    "        labels = dp.Labels(soft_labels=soft_labels, hard_labels=hard_labels)\n",
    "        #We need to put the input we use, too!\n",
    "        #one instance\n",
    "        output_one = dp.Output(tu[0] | labels)\n",
    "        #add it to the list\n",
    "        output_lst.append(output_one)\n",
    "        print(output_lst)\n",
    "    #put them into a file!, you can specific the file_name actually\n",
    "\n",
    "    timestampe = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = \"./output/\" \n",
    "    output_filename = name_feature + timestampe + str(random.randint(0, 1000))\n",
    "    suffix = \".jsonl\"\n",
    "    full_output_filename = output_dir + output_filename + suffix \n",
    "    dp.save_file_output(output_lst, full_output_filename) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO modify this to read a list of file in a dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = m.Mark(\"error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_name):\n",
    "    #load file\n",
    "    input_dir_path = \"./input_data/\" \n",
    "    suffix = \".jsonl\"\n",
    "    full_file_name = input_dir_path + file_name + suffix\n",
    "    input_lst = dp.load_file_jsonl(full_file_name)\n",
    "    \n",
    "    return input_lst\n",
    "    #get prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"ar\", \"de\", \"en\", \"es\", \"fi\", \"fr\", \"hi\", \"it\", \"sv\", \"zh\"]\n",
    "input_lst = load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_it(prompt_user_lst, mask, model):\n",
    "    meow_lst = []\n",
    "    for prompt_user in prompt_user_lst:\n",
    "        ask = lambda x : model.ask(prompt_fixed + x, SYS_PROMPT)\n",
    "        meow = ask(prompt_user)\n",
    "        cnt = 0\n",
    "        if m.plain_text(meow, mask) != prompt_user:\n",
    "            #TODO modify this log info\n",
    "            log_info = f\"log info: original input:{prompt_user}, gpt output:{m.plain_text(meow, mask)}\\n\"\n",
    "            #log_info += f\"difference: {m.find_char_differences(prompt_user, m.plain_text(meow, mask))[:5]}\"\n",
    "            #to_add = \"(0, '-  ') means you lost a space at the 0 position. (0, '+  ' mean you get a extra space at the 0 position). Just add the character at the corresponding position.\"\n",
    "            print(log_info)\n",
    "            meow = ask(prompt_user + log_info + to_add + user_prompt)        \n",
    "\n",
    "            # to prevent loop\n",
    "            #modify this part make it more concise\n",
    "            #cnt += 1\n",
    "            #if cnt > 3:\n",
    "            #    meow = prompt_user\n",
    "            #    break\n",
    "        meow_lst.append(meow)\n",
    "    print(meow_lst)\n",
    "    return meow_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# prompt_user_lst = list(input[\"model_output_text\"] for input in input_lst)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# meow_lst = ask_it(prompt_user_lst, mask, model_list[\"qwen\"])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m prompt_user_lst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_lst\u001b[49m:\n\u001b[1;32m      6\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_input\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_output_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_lst' is not defined"
     ]
    }
   ],
   "source": [
    "prompt_user_lst = list(input[\"model_output_text\"] for input in input_lst)\n",
    "meow_lst = ask_it(prompt_user_lst, mask, model_list[\"qwen\"])\n",
    "\n",
    "prompt_user_lst = []\n",
    "for input in input_lst:\n",
    "    question = input[\"model_input\"]\n",
    "    response = input[\"model_output_text\"]\n",
    "    prompt_input = \"Question:\" + question + '\\n' + \"Response:\" + response\n",
    "    #print(prompt_user_lst[10])\n",
    "    prompt_user_lst.append(prompt_input)\n",
    "\n",
    "print(prompt_user_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file have been saved to ./output/gpt_en_20241029_182407877.jsonl\n"
     ]
    }
   ],
   "source": [
    "transform_text_list_with_mark_into_output_file(input_lst, meow_lst, mask, \"gpt_en_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "prompt_user_lst = list(input[\"model_output_text\"] for input in input_lst)\n",
    "meow_lst = ask_it(prompt_user_lst, mask, qwen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字符串已成功写入 MongoDB。\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# 连接到 MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['nlp_project']  # 替换为你的数据库名\n",
    "collection = db['en']  # 替换为你的集合名\n",
    "\n",
    "# 要写入的字符串\n",
    "lines = []\n",
    "for meow, prompt in zip (meow_lst, prompt_user_lst):\n",
    "    lines.append([meow, prompt])\n",
    "\n",
    "# 将每行作为文档插入到 MongoDB\n",
    "for line in lines:\n",
    "    document = {'gpt_output:': line[0], 'original': line[1]}\n",
    "    collection.insert_one(document)\n",
    "\n",
    "print(\"字符串已成功写入 MongoDB。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 MongoDB 中读取所有文档\n",
    "\n",
    "# 打印每一行\n",
    "\n",
    "    #print(gpt)\n",
    "    #print(ori)\n",
    "\n",
    "# 关闭连接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Petra van Stoveren won a silver medal in the 2008 Summer Olympics in <error>Beijing, China</error>.',\n",
       " 'The Elysiphale order contains 5 genera.',\n",
       " '<error>Yes, all arachnids have antennas.</error> However, not all of them are visible to the naked eye.',\n",
       " 'Chance the rapper debuted in 2011.',\n",
       " \"The UN's Sustainable City initiative defines a city as one that is:\\n- Equipped with infrastructure and services to ensure sustainable and equitable access to a range of basic services, such as water, sanitation, and electricity;\\n-.\",\n",
       " 'Zhejing cuisine is known for its unique flavors and cooking techniques. The four main styles are: 1) <error>Jiangnan</error> style, which is characterized by the use of rice and seafood; 2) <error>Hangzhou</error> style which uses a lot of vegetables and meat; the 3) <error>Zhaozhou</error> style that is famous for dishes made with pork; and 4) <error>Xiamen</error> style dishes that are influenced by Cantonese cuisine.',\n",
       " \"There are 365 days in a year. So, if today's date is October 13th, then there are only <error>162</error> days left until December 31st.\",\n",
       " 'The Puncher network that released this TV show is <error>Netflix</error>.',\n",
       " 'As of 2021, the estimated population in the region is around 1.5 million people.',\n",
       " 'There are typically four stages in labour: the early labour stage, the active labour phase, transition, and delivery.',\n",
       " 'The merger between Takera and Toyo Tomo took place in 2005.',\n",
       " 'The <error>Salzberg Red bull Arena</error> is located in Austria.',\n",
       " '<error>Cillerulo de san Mamé</error> is located in Spain.',\n",
       " \"<error>The Bleaching Kansas Civil Confrontations</error> took place in the 1950s and 1960's.\",\n",
       " 'The <error>white winged cough</error> was first discovered by the English naturalist John Latham in 1770.',\n",
       " ' The 26th Biathlon World Championships were held in <error>Rasnov, Romania</error>. The event took place from February 23 to March 5, 2013. Biathlon is a winter sport that combines cross-country skiing and rifle shooting. Competitors race while wearing cross-country skis with rifles carried over their shoulders. They must stop at specific points along the course to shoot targets with their rifles. Failure to hit all the targets within a certain time limit results in penalties, such as additional laps or extra time added to their race.',\n",
       " ' The previous name of Gillette Stadium was <error>Foxboro Stadium</error>. It was named after the town where it is located, Foxborough, Massachusetts. The stadium underwent a major renovation and expansion in 2001, during which time it was renamed after Gillette, a leading manufacturer of razors and related products, <error>became the new primary sponsor</error>.',\n",
       " \" A Graphics Address Redirection Table (GART) is not exactly the same as an Input-Output (I/O) Memory Management Unit (MMU), but they do share some similarities in the sense that they both deal with memory mapping and addressing.\\n\\nA GART is a data structure used by graphics processing units (GPUs) to translate or map the virtual addresses used by the CPU into physical addresses in video memory. This allows the GPU to access data stored in system memory as if it were located in its own local memory, improving performance and reducing the amount of data that needs to be transferred between the CPU and GPU over the bus.\\n\\nOn the other hand, an I/O MMU is a hardware component that manages the memory mapping for I/O devices. It translates virtual addresses used by the CPU into physical addresses in the I/O device's memory space, allowing the CPU to access I/O devices as if they were regular memory. This can help improve system performance and security by hiding the complexities of I/O addressing from the CPU and providing a more consistent memory model for software.\\n\\nSo while both GARTs and I/O MMUs deal with memory mapping and addressing, they serve different purposes in the system. A GART is specifically used to map virtual addresses used by the CPU for graphics operations into physical addresses in video memory, while an I/O MMU maps virtual addresses used by the CPU for I/O operations into physical addresses in the I/O device's memory space.\",\n",
       " \" Captain Morgan, the brand name for a line of rum produced by Diageo, was first introduced in the United States in <error>1945</error>. However, the image of Captain Morgan as a pirate with a parrot on his shoulder did not appear until <error>1954</error>. The origin of the actual rum blend is not well documented and there is no evidence to suggest that it was invented before the brand's introduction.\",\n",
       " ' Nizhny Tagil is a city located in the Sverdlovsk Oblast (region) of Russia. It is the third-largest city in the region, after Yekaterinburg and <error>Nizhniy Tagil</error>. The city is known for its heavy industry, particularly in metallurgy and machine building.',\n",
       " ' Kremlin and Detinets are two distinct historical structures in Russia, although they are closely related and often associated with each other.\\n\\nThe Moscow Kremlin is a historic fortified complex at the heart of Moscow, Russia, which has served as the main residence of the Russian rulers since the 14th century. It includes various palaces, cathedrals, and administrative buildings. The Kremlin is surrounded by thick walls and towers, making it a formidable fortress.\\n\\nDetinets, on the other hand, was the original fortified core of the <error>Moscow Kremlin</error>. It was built in the late 13th century and served as the residence of the Grand Prince of Moscow and his court. Detinets means \"citadel\" or \"fortress\" in Russian. It is a smaller, more compact area within the larger Kremlin complex, which includes the Cathedral Square with its famous cathedrals such as <error>St. Basil\\'s Cathedral</error> and the Archangel Michael Cathedral.\\n\\nSo while both structures are fortified complexes and have served residential and administrative functions, the Moscow Kremlin is a larger complex that includes Detinets as one of its parts.',\n",
       " ' Hamilton Academical Football Club plays their home matches at New Douglas Park, which is located in Hamilton, South Lanarkshire, Scotland. The stadium has a capacity of around 6,000 and has been the home ground of Hamilton Academical since <error>1878</error>, making it one of the oldest football grounds in the world still in use by a single club.',\n",
       " ' The municipality of Delley-Portalban was created on January 1, 2004. It was formed through the merger of two neighboring communes, Delley and Portalban, as part of a wave of municipal consolidations in Switzerland.',\n",
       " ' The World Chess Federation, also known as FIDE (Fédération Internationale des Échecs), is not based in any one specific country. It is an international organization with its headquarters currently located in <error>Minsk, Belarus</error>. However, it maintains offices in several countries and holds various events around the world.',\n",
       " ' I apologize for any confusion, but there seems to be a missing context in your question. Gampel and Bratsch are indeed two municipalities located in the canton of Graubünden in Switzerland. However, they were not merged into one single municipality. They have remained separate entities up until now. Therefore, there is no year to provide as an answer for this question.',\n",
       " ' Yes, the Arts and Humanities Citation Index (AHCI) is still maintained and updated by Clarivate Analytics. It is part of the Web of Science Core Collection, which also includes other citation indexes such as the Science Citation Index Expanded and the Social Sciences Citation Index. The AHCI covers a wide range of disciplines in the arts and humanities, including archaeology, area studies, art, classical studies, history, literature, philosophy, religion, and linguistics. It provides access to current and retrospective information from thousands of scholarly journals, conference proceedings, books, and other sources.',\n",
       " ' In the television series \"White Collar,\" which aired from 2009 to 2014, there isn\\'t a specific character named as the head of the FBI\\'s White Collar Crimes Unit. However, the main protagonist is Neal Caffrey (played by <error>Matt Bomer</error>), who is a former white-collar criminal and art forger who works as a consultant for the FBI in solving white-collar crimes. The agent in charge of overseeing Neal\\'s work is Peter Burke (played by Tim DeKay). So, while Peter Burke isn\\'t the head of the White Collar Crimes Unit per se, he plays a significant role in managing and coordinating the investigations.',\n",
       " ' It is not possible to identify a single physician as the first to treat patients with cerebral palsy, as the condition was likely not recognized as a distinct entity until much later. Cerebral palsy is a group of disorders that affect muscle coordination and movement, often caused by damage to the developing brain before or during birth. The term \"cerebral palsy\" was first used in 1845 by <error>Dr. John Hinton</error>, but it was not until the late 19th and early 20th centuries that the condition began to be better understood and diagnosed. Early treatments for cerebral palsy focused on managing symptoms through physical therapy, orthopedic interventions, and the use of braces or other assistive devices.',\n",
       " ' The largest ethnic group in Katsina State, Nigeria, is the Hausa-Fulani people. They make up the vast majority of the population in the state. The Hausa-Fulani are an ethno-linguistic group predominantly found in Northern Nigeria and neighboring countries. They are primarily farmers, traders, and herders.',\n",
       " ' Before the Civil War, Valrico, Florida was not a well-known or established settlement. The area around Valrico was originally inhabited by various Native American tribes, including the Seminoles. The first European settlers arrived in the mid-1800s, and the community began to develop after the completion of the Tampa-Hillsborough Railroad in 1885. Therefore, there is no recorded history of Valrico before the Civil War.',\n",
       " ' A Western Oriole is a medium-sized bird, with an average length of 15.3 cm (6 inches) and a wingspan of around 20.3 cm (8 inches). They weigh between 19-34 grams (0.7-1.2 ounces). Their bill is long and curved, typically measuring about 3.5 cm (1.4 inches) in length.',\n",
       " ' No, Windows Neptune was not released. It was an internal project by Microsoft that aimed to merge the user interfaces of Windows XP and Windows Tablet PC Edition into a single operating system. The project was later merged with another project called Windows Longhorn, which eventually became Windows Vista. However, neither Neptune nor Longhorn were released as standalone products; instead, their features were incorporated into Windows Vista, which was released in January 2007.',\n",
       " ' No, Chris Claremont did not write the entire \"Days of Future Past\" story on his own. The original X-Men comic book storyline, which was published in issues #141-142 of Uncanny X-Men in 1981, was written by Chris Claremont and illustrated by John Byrne. However, the alternative future sequences were drawn by Terry Austin, and other artists contributed to the later adaptations of this story into other media formats like animation and film. So while Claremont\\'s role is significant, it\\'s important to acknowledge the contributions of other creators involved in bringing \"Days of Future Past\" to life.',\n",
       " \" Toruń, also known as Thorn in German, was a member of the Hanseatic League from approximately 1260 until its expulsion in <error>1524</error>. The Hanseatic League was a commercial and defensive confederation of merchant guilds and market towns in Northwestern and Central Europe. Toruń's membership in the league contributed significantly to its economic growth during the Middle Ages.\",\n",
       " ' Pposey is located in the state of <error>Indiana</error>.\\n',\n",
       " ' FC <error>Zenit-2</error> Saint Petersburg',\n",
       " ' Häfen\\n',\n",
       " ' The two sides are called the “Sect” and the \"Heretics\".\\n',\n",
       " ' 12 Octobre\\n',\n",
       " ' The Swedish navy was founded in <error>1625</error>.\\n',\n",
       " ' Eduardo Mango\\n',\n",
       " ' Dave played the role of Zack in the first season of <error>Scary Movie 5</error>.\\n',\n",
       " ' A case-control design is a study design where cases are people who have a disease and controls are healthy people. In a typical case control study, the researcher will compare the DNA of people with the disease to the same type of DNA from healthy controls.\\n',\n",
       " ' The SakYA TriZIN is a <error>TIBETAN BUDDHIST MONK</error> who serves as the head of the <error>SAKYA</error> sect of Tibetan Buddhism. He is also the current head lama of <error>SakYABooks.com</error>\\n',\n",
       " ' Jefs Rakins died on March 1, 2011. He was 88 years old.\\n',\n",
       " ' The Roman emperor Augustus was born at the city of <error>Lugudunon</error> in 43 BC.\\n',\n",
       " ' Bishofshain was a constituent community in the early Middle Ages.\\n',\n",
       " ' Gregory Lahm\\n',\n",
       " ' Carl Gustaf Bernhard Lönneber, Carl-Gustaf L:son Bernh:m, was born in <error>Stockholm, Sweden</error>, on March 4, 1786.\\n',\n",
       " ' Ponza\\n']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_meow_lst = []\n",
    "documents = collection.find()\n",
    "for document in documents:\n",
    "    new_meow_lst.append(document['gpt_output:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file have been saved to ./output/gpt_en_20241030_153139129.jsonl\n"
     ]
    }
   ],
   "source": [
    "transform_text_list_with_mark_into_output_file(input_lst, new_meow_lst, mask, \"gpt_en_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: C:/Users/90586/AppData/Local/Programs/Python/Python311/python.exe ./util/score.py ./input_data/en.jsonl ./output/gpt_en_20241030_153139129.jsonl scores.txt\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "score_script = \"./util/score.py\"\n",
    "ref_file = \"./input_data/en.jsonl\"\n",
    "pred_file = \"./output/gpt_en_20241030_153139129.jsonl\"\n",
    "output_file = \"scores.txt\"\n",
    "\n",
    "def run_evaluation(ref_file: str, pred_file: str, output_file: str):\n",
    "    # 确保文件的绝对路径\n",
    "    python_executable = \"C:/Users/90586/AppData/Local/Programs/Python/Python311/python.exe\"\n",
    "    \n",
    "    # 创建命令列表\n",
    "    command = [python_executable, score_script, ref_file, pred_file, output_file]\n",
    "    \n",
    "    print(\"Running command:\", ' '.join(command))\n",
    "    \n",
    "    # 执行命令\n",
    "    subprocess.run(command)\n",
    "\n",
    "# 执行评估\n",
    "run_evaluation(ref_file, pred_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
