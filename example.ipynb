{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import qwen\n",
    "import util.mark as m\n",
    "import util.data_processing as dp\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1. choose a model, you can specify api key, specific model i.e. qwen-plus etc.\n",
    "you can use gpt.GPT() as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qwen = qwen.Qwen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Prepare input\n",
    "You can load data from /input_data using dp.load_file_jsonl(filepath)\n",
    "\n",
    "Pay attention to the file suffix: jsonl!\n",
    "\n",
    "You can specify the prompt_user as input and prompt_system as some instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system = \"\"\"Given a passage, identify any <entity>, <relation>, <contradictory>, <subjective>, <unverifiable>, or <invented> errors in the passage. Mark each erroneous segment by enclosing it within the corresponding <error_type></error_type> tags. If there are no errors, return the passage with no tags. Any identified errors should be highlighted using the specified tags without altering the original text. Below are the error definitions followed by an example of the required format.\n",
    "\n",
    "Definitions:\n",
    "\n",
    "Entity Error (<entity>): A small part of a sentence, often an entity (e.g., location name), is incorrect (usually 1-3 words). Entity errors often involve noun phrases or nouns.\n",
    "Relational Error (<relation>): A sentence is partially incorrect due to a small part (usually 1-3 words). Relational errors often involve verbs and are often the opposite of what they should be.\n",
    "Contradictory Sentence Error (<contradictory>): A sentence where the entire content is contradicted by the given reference, meaning the sentence can be proven false due to a contradiction with information in the passage.\n",
    "Invented Info Error (<invented>): Errors referring to entities that are not known or do not exist. This does not include fictional characters in books or movies. Invented errors include phrases or sentences with unknown entities or misleading information.\n",
    "Subjective Sentence (<subjective>): An entire sentence or phrase that is subjective and cannot be verified, so it should not be included.\n",
    "Unverifiable Sentence (<unverifiable>): A sentence where the whole sentence or phrase is unlikely to be factually grounded. Although it can be true, the sentence cannot be confirmed nor denied using the reference given or internet search. It is often something personal or private and hence cannot be confirmed.\n",
    "\n",
    "##\n",
    "Passage: Marooned on Mars is a science fiction novel aimed at a younger audience. It was written by Andy Weir and published by John C. Winston Co. in 1952, featuring illustrations by Alex Schomburg. It ended up having a readership of older boys despite efforts for it to be aimed at younger kids. The novel inspired the famous Broadway musical \"Stranded Stars,\" which won six Tony Awards. The novel tells a story of being stranded on the Purple Planet. I wish the novel had more exciting and thrilling plot twists.\n",
    "Edited: Marooned on Mars is a science fiction novel aimed at a younger audience.\n",
    "It was written by <entity>Lester del Rey</entity> and published by John C. Winston Co. in 1952, featuring illustrations by Alex Schomburg.\n",
    "<contradictory>It ended up having a readership of older boys despite efforts for it to be aimed at younger kids.</contradictory>\n",
    "<invented>The novel inspired the famous Broadway musical \"Stranded Stars,\" which won six Tony Awards.</invented>\n",
    "The novel tells a story of being stranded on the <entity>Purple</entity> Planet.\n",
    "<subjective>I wish the novel had more exciting and thrilling plot twists.</subjective>\n",
    "##\n",
    "\n",
    "Instructions: Now detect errors and include tags in the following passage as demonstrated in the example above. Use <error_type></error_type> tags around each identified error segment. If there are no errors, return the passage unchanged.\n",
    "\n",
    "Passage:\n",
    "The restoration of S\\u00e1ndor Palace, also known as the Buda Castle, was completed in several phases. The most significant restoration took place between 1950 and 1961 under the supervision of Hungarian architects Gy\\u0151z\\u0151 Csapl\\u00e1r and Lajos K\\u00e9sm\\u00e1rki. However, it's important to note that various parts of the palace continued to be restored and renovated throughout the decades following this period. Therefore, it is not accurate to pinpoint an exact completion date for the entire restoration project.\n",
    "\n",
    "Edited:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3. Load file from input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "tagged_text: \" The restoration of Sándor Palace, also known as the <entity>Buda Castle</entity>, was completed in several phases. The most significant restoration took place between <invented>1950 and 1961</invented> under the supervision of <entity>Hungarian architects Győző Csaplár and Lajos Késmárki</entity>. However, it's important to note that various parts of the palace continued to be restored and renovated throughout the decades following this period. Therefore, it is not <subjective>accurate</subjective> to pinpoint an exact completion date for the entire restoration project.\"\n",
      "errors: [{'type': 'entity', 'start': 54, 'end': 82, 'text': 'Buda Castle'}, {'type': 'entity', 'start': 229, 'end': 299, 'text': 'Hungarian architects Győző Csaplár and Lajos Késmárki'}, {'type': 'invented', 'start': 169, 'end': 203, 'text': '1950 and 1961'}, {'type': 'subjective', 'start': 472, 'end': 505, 'text': 'accurate'}]\n",
      "id: 3\n",
      "tagged_text: \" Yes, Scotland made their debut in the UEFA Euro 1996 qualifying phase. This was their first appearance in a European Championship qualifying campaign since the inception of the UEFA European Football Championship in 1960. Scotland finished <invented>third</invented> in their group behind <entity>England</entity> and <entity>Switzerland</entity>, missing out on qualification for the tournament.\"\n",
      "errors: [{'type': 'entity', 'start': 291, 'end': 315, 'text': 'England'}, {'type': 'entity', 'start': 320, 'end': 348, 'text': 'Switzerland'}, {'type': 'invented', 'start': 242, 'end': 268, 'text': 'third'}]\n",
      "id: 4\n",
      "tagged_text: \" L'équipe d'Azerbaïdjan n'a pas participé à l'Euro 1996 car elle n'était pas encore redevenue indépendante et n'avait donc pas pu se qualifier pour la compétition. L'Azerbaïdjan a obtenu son indépendance en 1991, mais il fallut attendre <invented>2009</invented> avant que l'équipe puisse participer à une compétition internationale majeure, les Qualifications pour le Championnat d'Europe de football <invented>2012</invented>.\"\n",
      "errors: [{'type': 'invented', 'start': 238, 'end': 263, 'text': '2009'}, {'type': 'invented', 'start': 403, 'end': 428, 'text': '2012'}]\n",
      "id: 8\n",
      "tagged_text: \"8437 Bernicla est-il un objet transneptunien? La découverte de l'objet <invented>8436 Berniccila</invented> en 1988 a suscité un intérêt particulier car il s'agit d'un objet qui se trouve dans la ceinture de Kuiper, zone du système solaire où se trouvent les objets trans-Neptuniens (OTN). Cependant, la classification d'<entity>OTNe</entity> de <entity>Bernicia</entity> a été contestée par certains astronomes et la question de savoir si <entity>Bernica</entity> est un OTNe ou non a longtemps été débattue. La ceINTURE de KUIPER\"\n",
      "errors: [{'type': 'entity', 'start': 322, 'end': 343, 'text': 'OTNe'}, {'type': 'entity', 'start': 347, 'end': 372, 'text': 'Bernicia'}, {'type': 'entity', 'start': 441, 'end': 465, 'text': 'Bernica'}, {'type': 'invented', 'start': 72, 'end': 108, 'text': '8436 Berniccila'}]\n",
      "id: 9\n",
      "tagged_text: \" Xiong Ai was a Chinese warlord who lived during the Warring States period (475-221 BC). He ruled over the state of <entity>Xiongnu</entity>, which is modern-day Mongolia rather than a Chinese state. The Xiongnu were an influential nomadic confederation that posed a significant threat to China during this time. Therefore, Xiong Ai's rule was not over a Chinese state but rather over the <entity>Xiongnu</entity> people.\"\n",
      "errors: [{'type': 'entity', 'start': 117, 'end': 141, 'text': 'Xiongnu'}, {'type': 'entity', 'start': 390, 'end': 414, 'text': 'Xiongnu'}]\n",
      "id: 10\n",
      "tagged_text: \"El palais Sândor (también conocido como Palais Barcsay o Palacio Baracsay) es un palacete histórico ubicado en el barrio de Buda de Budapest, en la calle Szent György. Fue construido a finales del siglo XIX y fue propiedad de la familia Barcza. En 1904, fue comprado por el empresario húngaro Sándór Baróczy, de quien toma su nombre actual. El <entity>palace</entity> fue <entity>construida</entity> en un estilo neoclásico, con una fachada de estilo Renacimiento italiano. Desde 2012, el <entity>Palácio Sândor</entity> ha sido la <relation>residencial oficial</relation> de los presidentes de <entity>República Húngara</entity>.\n",
      "\n",
      "¿Cuándó se convirtió el edificio en residencias presidenciales?\n",
      "En 1991, después de que el gobierno comunista cayera en <entity>Hun-gría</entity>, se aprobó una ley que establecía que la sede presidencial debía estar en <entity>Bucarest</entity>. Sin embargo, debido a la falta de instalaciones adecuadas, los gobiernos sucesivos decidieron que los Presidentes continuarían residiendo en sus propias casas. No fue hasta 2006 que se tomó la decisión de convertir el <entity>Castillo de Sissak</entity> (Buda) en una <entity>residensia</entity> oficial para los <entity>Presi dentes</entity>, pero esto nunca se materializó. Finalmente, a principios de <entity>2 012</entity>, la oficina del presidente decidió que un <entity>edificado</entity> adecuada para la función de <relation>residenciar</relation> a los líderes húngaros ya existía en forma del <entity>Palaceto Sando r</entity>, que fue renovado para albergar a las familias presiden ciales.\"\n",
      "errors: [{'type': 'entity', 'start': 345, 'end': 368, 'text': 'palace'}, {'type': 'entity', 'start': 373, 'end': 400, 'text': 'construida'}, {'type': 'entity', 'start': 490, 'end': 521, 'text': 'Palácio Sândor'}, {'type': 'entity', 'start': 596, 'end': 630, 'text': 'República Húngara'}, {'type': 'entity', 'start': 753, 'end': 778, 'text': 'Hun-gría'}, {'type': 'entity', 'start': 853, 'end': 878, 'text': 'Bucarest'}, {'type': 'entity', 'start': 1098, 'end': 1133, 'text': 'Castillo de Sissak'}, {'type': 'entity', 'start': 1148, 'end': 1175, 'text': 'residensia'}, {'type': 'entity', 'start': 1193, 'end': 1222, 'text': 'Presi dentes'}, {'type': 'entity', 'start': 1284, 'end': 1306, 'text': '2 012'}, {'type': 'entity', 'start': 1349, 'end': 1375, 'text': 'edificado'}, {'type': 'entity', 'start': 1484, 'end': 1517, 'text': 'Palaceto Sando r'}, {'type': 'relation', 'start': 533, 'end': 573, 'text': 'residencial oficial'}, {'type': 'relation', 'start': 1404, 'end': 1436, 'text': 'residenciar'}]\n",
      "id: 11\n",
      "tagged_text: \"El país que logra clasificarse en el último puesto en la fase de clasificación para la <contradictory>Copa Mundial de la FIFA 2014</contradictory> fue <entity>Australia</entity>, ya que terminó en cuarto lugar en su grupo de AFC, solo por delante de <entity>China</entity>, <entity>Corea del Sur</entity> y <entity>Tailandia</entity>. Sin embargo, Australia no participó realmente en los <invented>play-off</invented>, sino que se clasifica automáticamente para el torneo debido a su estatus como miembro de las zonas de Asia y Oceanía.\"\n",
      "errors: [{'type': 'entity', 'start': 152, 'end': 178, 'text': 'Australia'}, {'type': 'entity', 'start': 251, 'end': 273, 'text': 'China'}, {'type': 'entity', 'start': 275, 'end': 305, 'text': 'Corea del Sur'}, {'type': 'entity', 'start': 308, 'end': 334, 'text': 'Tailandia'}, {'type': 'contradictory', 'start': 88, 'end': 147, 'text': 'Copa Mundial de la FIFA 2014'}, {'type': 'invented', 'start': 389, 'end': 418, 'text': 'play-off'}]\n",
      "id: 12\n",
      "tagged_text: \"Los <entity>miudades</entity> de <entity>Cladotholus</entity>, <entity>Cladoscypha</entity> y <entity>Cladiopelma</entity> son todos <entity>miembro</entity> de las <entity>Cladoriaceae</entity>. Estos <entity>miércoles</entity> presentaban características únicas que los diferenciaban de otros <entity>miembres</entity> de su familia.\n",
      "\n",
      "<entity>Cladothus</entity> es una especie de <entity>líbano</entity> que se encuentra en climas desérticos. Se caracteriza por sus hojas verdes y gruesas que pueden crecer hasta 30 cm de longitud. También tiene un tallo carnoso que puede almacenar agua durante largos periodos de tiempo, lo que lo convierte en un excelente candidato para su uso en paisajismo en regiones áridas.\n",
      "\n",
      "Por otro lado, <entity>la Cladia</entity> es un género de hongos que crece en grupos en árboles y arbustos. Sus cuerpos fructíferos son pequeños y tienen forma de dedos, con una coloración amarilla o naranja brillante. <entity>La Clada</entity> también tiene una estructura única llamada \"sistema de cladiocistos\", que le permite reproducirse tanto sexual como asexualmente.\n",
      "\n",
      "Finalmente, el <entity>Claudiopella</entity> es otro <entity>géneros</entity> fúngicos que también crecen en plantas. Tienen una apariencia parecida a plumas y pueden ser de varios colores, incluyendo rojo, amarronado y verde. <entity>Su estructuras frutales son distintivas en forma y usualmente se encuentran en grandes grupos.</entity>\n",
      "\n",
      "En general, estos <entity>miérmes</entity> de los <entity>Cladores</entity> son únicos en su <subjective>apreción y presentación</subjective>, mostrando las diversas y fascinantes características de sus respectivos <entity>géneos</entity>.\"\n",
      "errors: [{'type': 'entity', 'start': 5, 'end': 30, 'text': 'miudades'}, {'type': 'entity', 'start': 34, 'end': 62, 'text': 'Cladotholus'}, {'type': 'entity', 'start': 64, 'end': 92, 'text': 'Cladoscypha'}, {'type': 'entity', 'start': 95, 'end': 123, 'text': 'Cladiopelma'}, {'type': 'entity', 'start': 134, 'end': 158, 'text': 'miembro'}, {'type': 'entity', 'start': 166, 'end': 195, 'text': 'Cladoriaceae'}, {'type': 'entity', 'start': 203, 'end': 229, 'text': 'miércoles'}, {'type': 'entity', 'start': 296, 'end': 321, 'text': 'miembres'}, {'type': 'entity', 'start': 338, 'end': 364, 'text': 'Cladothus'}, {'type': 'entity', 'start': 383, 'end': 406, 'text': 'líbano'}, {'type': 'entity', 'start': 734, 'end': 760, 'text': 'la Cladia'}, {'type': 'entity', 'start': 938, 'end': 963, 'text': 'La Clada'}, {'type': 'entity', 'start': 1110, 'end': 1139, 'text': 'Claudiopella'}, {'type': 'entity', 'start': 1148, 'end': 1172, 'text': 'géneros'}, {'type': 'entity', 'start': 1322, 'end': 1433, 'text': 'Su estructuras frutales son distintivas en forma y usualmente se encuentran en grandes grupos.'}, {'type': 'entity', 'start': 1453, 'end': 1477, 'text': 'miérmes'}, {'type': 'entity', 'start': 1485, 'end': 1510, 'text': 'Cladores'}, {'type': 'entity', 'start': 1650, 'end': 1673, 'text': 'géneos'}, {'type': 'subjective', 'start': 1528, 'end': 1576, 'text': 'apreción y presentación'}]\n"
     ]
    }
   ],
   "source": [
    "file_name = \"en\"\n",
    "input_lst = dp.load_file_jsonl(\"./input_data/\" + file_name + \".jsonl\")\n",
    "prompt_user_lst = list(input[\"model_output_text\"] for input in input_lst)\n",
    "print(prompt_user_lst[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4. Register some marks\n",
    "I want to use my own mark like <mask>, how to do it?\n",
    "\n",
    "Just use m.Mark(\"mask\") to make one.\n",
    "\n",
    "i.e. mask = Mark(\"mask\")\n",
    "\n",
    "i.e. mask.s == &lt; mask &gt;\n",
    "\n",
    "i.e. mask.e == &lt;/ mask &gt;\n",
    "\n",
    "like: &lt; entity &gt;, &lt; relation &gt;, &lt; contradictory &gt;, &lt; subjective &gt;, &lt; unverifiable &gt;, or &lt; invented &gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = m.Mark(\"entity\")\n",
    "relation = m.Mark(\"relation\")\n",
    "contradictory = m.Mark(\"contradictory\")\n",
    "subjective = m.Mark(\"subjective\")\n",
    "unverifiable = m.Mark(\"unverifiable\")\n",
    "invented = m.Mark(\"invented\")\n",
    "#this should be erased in the output part\n",
    "#user plain_text() in m package!\n",
    "not_mask_lst = [entity, relation, contradictory, unverifiable, invented]\n",
    "\n",
    "#my mask mark\n",
    "mask = m.Mark(\"mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. \n",
    "Get response by asking\n",
    "\n",
    "It's a str, response I mean.\n",
    "\n",
    "You can create a new class based on qwen or gpt to make your class and override the ask method to achieve your goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a test\n",
    "prompt = prompt_user_lst[0]\n",
    "meow = qwen.ask(prompt, prompt_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a test\n",
    "print(meow)\n",
    "for mark in not_mask_lst:\n",
    "    meow = m.plain_text(meow, mark)\n",
    "print(meow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meow_lst = []\n",
    "for prompt_user in prompt_user_lst:\n",
    "    meow = qwen.ask(prompt_user, prompt_system)\n",
    "    meow_lst.append(meow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6.\n",
    "Erase not <mask> marks!\n",
    "\n",
    "You need to remove these not mask mark!\n",
    "\n",
    "Because this will affect the function to get start and end label! i.e. starts_and_ends() func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plain_text_lst = []\n",
    "for meow in meow_lst:\n",
    "    for mark in not_mask_lst:\n",
    "        meow = m.plain_text(meow, mark)\n",
    "    plain_text_lst.append(meow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a test\n",
    "print(plain_text_lst[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7.\n",
    "Output!\n",
    "\n",
    "Put then into output file\n",
    "\n",
    "Corresponding input, list of output and the corresponding mark\n",
    "\n",
    "To give your a file with output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_text_list_with_mark_into_output_file(input_cor: List[str], text_lst: List[str], mark:m.Mark):\n",
    "    output_lst = []\n",
    "    input_and_output = zip(input_cor, text_lst)\n",
    "    for tu in input_and_output:\n",
    "        #get the hard_label i.e. [[12, 34], [34, 55] ...]\n",
    "        #tu[1] text, tu[1] cor_input\n",
    "        hard_labels = m.starts_and_ends(tu[1], mark)\n",
    "        #TODO I dont know how to deal with the fucking soft labels, just blank\n",
    "        #There soft label is empty, and hash_labels is just we got above.\n",
    "        labels = dp.Labels(soft_labels=dp.SoftLabel(), hard_labels=hard_labels)\n",
    "        #We need to put the input we use, too!\n",
    "        input = dp.Input(model_input=tu[0], model_output_text=tu[1])\n",
    "        #one instance\n",
    "        output_one = dp.Output(input | labels)\n",
    "        #add it to the list\n",
    "        output_lst.append(output_one)\n",
    "    #put them into a file!, you can specific the file_name actually\n",
    "    dp.save_file_output(output_lst)\n",
    "\n",
    "#do it!\n",
    "# Here you should use your own mark! not m.T\n",
    "transform_text_list_with_mark_into_output_file(prompt_user, plain_text_lst, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8. convert the hard_labels to soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "in_file = \"\"\n",
    "out_file = \"\"\n",
    "\n",
    "def convert_into_softlabels(in_file: str, out_file: str):\n",
    "    data = pd.read_json(in_file, lines=True)\n",
    "    soft_labels_list = []\n",
    "    for ele in data[\"hard_labels\"]:\n",
    "        soft_labels = []\n",
    "        for start, end in ele:\n",
    "            soft_labels.append({\"start\": start, \"prob\": 1.0, \"end\": end})\n",
    "        soft_labels_list.append(soft_labels)\n",
    "    data[\"soft_labels\"] = soft_labels_list\n",
    "    data.to_json(out_file, orient=\"records\", lines=True)\n",
    "\n",
    "convert_into_softlabels(in_file, out_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9.\n",
    "Calculate the score based on the score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "ref_file = \"mushroom.ar-val.v2.jsonl\"\n",
    "pred_file = \"qwen_ar20241029_0330473.jsonl\"\n",
    "output_file = \"scores.txt\"\n",
    "\n",
    "def run_evaluation(ref_file: str, pred_file: str, output_file: str):\n",
    "    command = f\"python3 util/score.py {ref_file} {pred_file} {output_file}\"\n",
    "    subprocess.run(command, shell=True)\n",
    "\n",
    "run_evaluation(ref_file, pred_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
